{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Words2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKug9HIKK3fpC2k27oZj+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanTokManMokMTM/NLP_Training4/blob/main/Words2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gurqneDTAv9"
      },
      "source": [
        "!unzip wiki_zh_2019\n",
        "#unzip the zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt7noXba87u-"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "import json\n",
        "ALL_DATAS = []\n",
        "filesList = {\n",
        "    0:\"AA\",\n",
        "    1:\"AB\",\n",
        "    2:\"AC\",\n",
        "    4:\"AD\",\n",
        "    5:\"AE\",\n",
        "    6:\"AF\",\n",
        "    7:\"AG\",\n",
        "    8:\"AH\",    \n",
        "    9:\"AI\",\n",
        "    10:\"AJ\",\n",
        "    11:\"AK\",\n",
        "    12:\"AL\",\n",
        "    13:\"AM\"\n",
        "}\n",
        "\n",
        "for i in filesList:\n",
        "  folderPath = \"./wiki_zh/%s/\" % filesList[i]\n",
        "  files = listdir(folderPath)\n",
        "  for i in files:\n",
        "    curFilePath = folderPath + \"%s\"%i \n",
        "    print(curFilePath)\n",
        "    with open(curFilePath) as f:\n",
        "      for j in f.readlines():\n",
        "        str2Json = json.loads(j)\n",
        "        text = \"\".join(str2Json[\"text\"].strip().split())\n",
        "        ALL_DATAS.append(text)\n",
        "      f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYpudYkjGhXQ"
      },
      "source": [
        "!pip install opencc-python-reimplemented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCbWRwDLHXFT"
      },
      "source": [
        "#convert text \n",
        "from opencc import OpenCC\n",
        "#convert to zh-hk\n",
        "ccConvertor = OpenCC(\"s2hk\")\n",
        "transChineseList = []\n",
        "for i in ALL_DATAS:\n",
        "  transChineseList.append(ccConvertor.convert(i))\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YdI4-yWCVTr"
      },
      "source": [
        "#store convertd data to csv\n",
        "import pandas as pd\n",
        "datas = pd.DataFrame(transChineseList)\n",
        "datas.to_csv(\"alldatas.csv\",encoding=\"utf-8\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQo3P3IVizE"
      },
      "source": [
        "# cut words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2GY2jGwXJqM",
        "outputId": "05721a24-a23d-4183-c390-93b9a7ac1fa1"
      },
      "source": [
        "!pip install jieba"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (0.42.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flknmXrPXraT"
      },
      "source": [
        "#load stopwords list\n",
        "import codecs \n",
        "fp = codecs.open(\"./stopwords.dat\",\"r\",encoding=\"utf-8\")\n",
        "contents = fp.read()\n",
        "fp.close()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaxTlIFXXLuM"
      },
      "source": [
        "import jieba\n",
        "import jieba.analyse\n",
        "cutWordsListDatas = []\n",
        "x = 0;\n",
        "for i in transChineseList:\n",
        "  cutWordsListDatas.append(\" \".join([word for word in jieba.cut(i,cut_all=False) if word not in contents]))\n",
        "  if(x%5000 == 0):\n",
        "    print(x)\n",
        "  x+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoMbd9mepzAE"
      },
      "source": [
        "cutWordsTxt = \"cutWordsList2.txt\"\n",
        "with open(cutWordsTxt,\"w\") as fw:\n",
        "  for data in cutWordsListDatas:\n",
        "    fw.write(data)\n",
        "    fw.write(\"\\n\")\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXYdX5McsRny"
      },
      "source": [
        "# Word2vec for our text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSOaOCvsVK6"
      },
      "source": [
        "!pip install word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elZcq8ILsclz",
        "outputId": "43034e6c-31c8-4805-840b-d026cb256f44"
      },
      "source": [
        "import word2vec\n",
        "#change our words to vector\n",
        "word2vec.word2vec(\"cutWordsList2.txt\",\"cutWords2Vec.bin\",size=300,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running command: word2vec -train cutWordsList2.txt -output cutWords2Vec.bin -size 300 -window 5 -sample 1e-3 -hs 0 -negative 5 -threads 12 -iter 5 -min-count 5 -alpha 0.025 -debug 2 -binary 0 -cbow 1\n",
            "Starting training using file cutWordsList2.txt\n",
            "Vocab size: 890060\n",
            "Words in train file: 124647462\n",
            "Alpha: 0.004841  Progress: 80.64%  Words/thread/sec: 58.73k  "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}